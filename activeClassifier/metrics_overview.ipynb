{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    def __init__(self, path, task, logname=\"log.log\", flagname='log_flags.pkl', verbose=False):\n",
    "        self.path = path\n",
    "        self.task = task\n",
    "        \n",
    "        self.flagfiles = [file for path, subdir, files in os.walk(os.path.join(path, task))\n",
    "                          for file in glob(os.path.join(path, flagname))]\n",
    "        if verbose:\n",
    "            print(self.flagfiles)\n",
    "        # logs = [file for path, subdir, files in os.walk(os.path.join(path, task))\n",
    "        #    for file in glob(os.path.join(path, logname))]\n",
    "        self.logfiles = [f.replace(flagname, logname) for f in self.flagfiles]\n",
    "\n",
    "        self.rename = {'binarize_MNIST': 'binarized',\n",
    "                       'normalise_fb': 'Nfb',\n",
    "                       'num_glimpses': 'glimpses',\n",
    "                       'num_classes_kn': 'KK',\n",
    "                       'num_uk_test': 'UU', \n",
    "                       'num_uk_test_used': 'UU used', \n",
    "                       'num_uk_train': 'KU',\n",
    "                       'scale_sizes': 'scales',\n",
    "                       'size_z': 'z size',\n",
    "                       'uk_cycling': 'cycl',\n",
    "                       'z_B_center': 'z center (B)',\n",
    "                       'z_dist': 'z dist'\n",
    "                      }\n",
    "            \n",
    "    def _rename(self, columns):\n",
    "        return [self.rename[c] if (c in self.rename.keys()) else c for c in columns]\n",
    "    \n",
    "    def _parse_results(self, file, keyword='TEST: '):\n",
    "        results = {}\n",
    "        with open(file, 'r') as f:\n",
    "            text = f.read()\n",
    "            test_log = re.findall('(?<={}).*(?=\\n)'.format(keyword), text)\n",
    "            if test_log:\n",
    "                final = test_log[-1].replace(':', '').split(' ')\n",
    "                for i in range(len(final) // 2):\n",
    "                    name = final[2*i].split('/')[-1]\n",
    "                    value = final[2*i + 1]\n",
    "                    results[name] = value\n",
    "        return results\n",
    "        \n",
    "    def get_overview(self, param_cols=None, metrics=None, groupby='glimpses', sortby=None, incl_last_valid=False):\n",
    "        rs = []\n",
    "        for log, flag in zip(self.logfiles, self.flagfiles):\n",
    "            with open(flag, 'rb') as f:\n",
    "                params = pickle.load(f)\n",
    "\n",
    "            results = self._parse_results(log)\n",
    "            if incl_last_valid:\n",
    "                results_valid = self._parse_results(log, keyword='VALID: ')\n",
    "                results.update({'val_' + k: v for k, v in results_valid.items()})\n",
    "                \n",
    "            exp_name = log.split('\\\\')[-2]\n",
    "            if results:\n",
    "                results.update(params)\n",
    "                results['exp_name'] = exp_name\n",
    "                rs.append(results)\n",
    "\n",
    "        if not rs:\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(rs)  \n",
    "        # df = df.set_index('name')\n",
    "        df['pre-train'] = df['pre_train_policy'] + df['pre_train_epochs'].astype(str)\n",
    "        df.columns = self._rename(df.columns)\n",
    "        df['scales'] = df['scales'].apply(lambda v: '{}x{}'.format(len(v), v[0]))\n",
    "        self.available_columns = sorted(df.columns)\n",
    "        \n",
    "        if param_cols is not None:\n",
    "            df = df.set_index(param_cols)\n",
    "    \n",
    "        if metrics is not None:\n",
    "            if incl_last_valid:\n",
    "                metrics += ['val_' + m for m in metrics]\n",
    "            df = df[metrics + [groupby]]\n",
    "            \n",
    "        df = df.pivot(columns=groupby).swaplevel(axis=1).sort_index(axis=1, level=0, sort_remaining=False)\n",
    "\n",
    "        if sortby is not None:\n",
    "            df = df.sort_values(sortby, ascending=False)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join('logs')\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['planner', 'scales', 'pre-train', 'z size', 'z dist', 'z center (B)', 'Nfb']\n",
    "metrics = ['acc', 'f1', 'loss', 'T']\n",
    "\n",
    "mnist = Aggregator(PATH, 'MNIST/rl', verbose=False)\n",
    "df = mnist.get_overview(params, metrics, sortby=(7, 'f1'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST_UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = ['planner', 'scales', 'pre-train', 'z size', 'z dist', 'z center (B)', 'Nfb', \n",
    "          'KK', 'KU', 'UU', 'UU used', 'cycl']\n",
    "metrics = ['f1', 'acc', 'acc_kn', 'acc_uk', 'loss', 'T', 'pct_noDecision']\n",
    "\n",
    "mnist_uk = Aggregator(PATH, 'MNIST_UK', verbose=False)\n",
    "df = mnist_uk.get_overview(params, metrics, sortby=(7, 'f1'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST_OMNI_notMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['planner', 'scales', 'pre-train', 'z size', 'z dist', 'z center (B)', 'Nfb', \n",
    "          'uk_pct', 'KK', 'KU', 'UU', 'binarized']\n",
    "metrics = ['f1', 'acc', 'acc_kn', 'acc_uk']\n",
    "\n",
    "mnist_omni_notmnist = Aggregator(PATH, 'MNIST_OMNI_notMNIST/rl')\n",
    "df = mnist_omni_notmnist.get_overview(params, metrics, sortby=(7, 'f1'), incl_last_valid=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
